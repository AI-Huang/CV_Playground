{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Date    : Aug-06-22 23:07\n",
    "# @Author  : Kelley Kan HUANG (kan.huang@connect.ust.hk)\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "base = os.path.abspath(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(base)\n",
    "from data.data_loader import load_data\n",
    "from data.rmnist import RMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99609375\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "training_data, validation_data, test_data = load_data(root=\".\", n=1)\n",
    "train_x, train_y = training_data[0], training_data[1]\n",
    "test_x, test_y = test_data[0], test_data[1]\n",
    "\n",
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "test_x = np.asarray(test_x)\n",
    "test_y = np.asarray(test_y)\n",
    "\n",
    "train_x = train_x.reshape((-1, 28, 28, 1))\n",
    "test_x = test_x.reshape((-1, 28, 28, 1))\n",
    "\n",
    "print(np.max(train_x))\n",
    "print(np.min(train_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import Augmentor\n",
    "data_augmentation = True\n",
    "# if data_augmentation:\n",
    "n_samples = 1024\n",
    "# data augmentation\n",
    "p = Augmentor.Pipeline()\n",
    "p.set_seed(42)  # args.seed\n",
    "p.rotate(probability=0.5, max_left_rotation=10,\n",
    "            max_right_rotation=10)\n",
    "p.random_distortion(probability=0.8, grid_width=3,\n",
    "                    grid_height=3, magnitude=2)\n",
    "p.skew(probability=0.8, magnitude=0.3)\n",
    "p.shear(probability=0.5, max_shear_left=3, max_shear_right=3)\n",
    "# Generate n_samples at one time\n",
    "generator = p.keras_generator_from_array(\n",
    "    train_x, train_y, n_samples, scaled=False)\n",
    "\n",
    "train_x, train_y = next(generator)\n",
    "\n",
    "train_x = np.clip(train_x, 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99609375\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(test_x))\n",
    "print(np.min(test_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4615452\n",
      "-0.4795931\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(train_x))\n",
    "print(np.min(train_x))\n",
    "train_x = np.clip(train_x, 0, 1)\n",
    "print(np.max(train_x))\n",
    "print(np.min(train_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {\"train_x\": train_x, \n",
    "            \"train_y\": train_y, \n",
    "            \"test_x\": test_x,\n",
    "            \"test_y\": test_y}\n",
    "\n",
    "with open(os.path.join(base, f'output/all_data_n{n_samples}.npy'), 'wb') as f:\n",
    "    np.save(f, all_data)\n",
    "\n",
    "config = {\"channel_format\": \"NCWH\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),  # Auto H x W x C to C x H x W\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = RMNIST(all_data, train=True, transform=transform)\n",
    "image, label = train_set[0]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.images.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = all_data[\"train_x\"][0]\n",
    "image.shape # BHW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26d9fdb7688>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_set = RMNIST(all_data, train=True, transform=transform)\n",
    "test_set = RMNIST(all_data, train=False, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
    "                                           shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # functions to show an image\n",
    "\n",
    "\n",
    "# def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# # get some random training images\n",
    "# dataiter = iter(train_loader)\n",
    "# images, labels = dataiter.next()\n",
    "\n",
    "# # show images\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "# # print labels\n",
    "# print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.torch_fn.lenet import LeNet5\n",
    "net = LeNet5(output_dim=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader) * 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     8] loss: 0.009\n",
      "[1,    16] loss: 0.009\n",
      "[2,     8] loss: 0.009\n",
      "[2,    16] loss: 0.009\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "print_every_steps = 8\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % print_every_steps == print_every_steps - 1:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, batch_idx + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "49023f40dda5c9950963a47c23103695f5c729d92da0eb5ffb23d739ed889c66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
